{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOVIES REVIEWS AND SENTIMENT ANALYSIS DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import urllib\n",
    "import urllib2\n",
    "import nltk\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from __future__ import division\n",
    "import io\n",
    "import numpy as np\n",
    "import html2text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie review are a list of html files saved in a local folder. The first step is to get all the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_list = []\n",
    "#direct = \"file:///C:\\Users\\s161328\\Downloads\\movie\\\\\"\n",
    "direct = \"/Users/Ferran/Downloads/movie/\"\n",
    "for f in listdir(direct):\n",
    "    if f.endswith(\".html\"):\n",
    "        filename_list.append(re.search(r'(.*?)\\.html', f).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the title of each movie is extracted. In this database, some titles have a reversed order (e.g. \"Godfather, The\" instead of \"The Godfather\"). In this cases, the title order is exchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles_list = [\"The\", \"A\", \"Les\", \"Il\", \"El\", \"Eles\", \"La\", \"Los\", \"Las\", \"De\", \"Das\", \"Den\", \"Die\", \"Det\", \"Der\", \n",
    "                 \"An\", \"Le\", \"L'\", \"Os\", \"Una\", \"O\", \"al-\", \"Lo\"]\n",
    "# Title filtered contains the title for each review, and if necessary, the title is put in the correct order\n",
    "title_filtered = []\n",
    "for f in filename_list:\n",
    "    try:\n",
    "        path = direct + f + \".html\"\n",
    "        \n",
    "        #t = urllib2.urlopen(path).read()\n",
    "        t = codecs.open(path,'r').read()\n",
    "        \n",
    "        soup = BeautifulSoup(t,'html.parser')\n",
    "        # The title of the movies has the format Review for __title__ (__year__)\n",
    "        title = re.search(r'Review for (.+) \\(', soup.title.string).group(1)\n",
    "        try:\n",
    "            # If a title contains a comma, and the right part is contained in articles list, the order is exchanged.\n",
    "            aux = re.search(r'(.+), (.+)', title)\n",
    "            before_comma = aux.group(1)\n",
    "            after_comma = aux.group(2)\n",
    "            if after_coma in articles_list:\n",
    "                title = after_comma + ' ' + before_comma\n",
    "        except:\n",
    "            pass\n",
    "        title_filtered.append(title)\n",
    "    except:\n",
    "        print(\"No title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to extract the review text. In the following part of the code, paragraph with review text are cleaned and joined in a single string. Finally, for the movies that already exist in the database, the list of reviews is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We start loading the movies dictionary obtained from Wikipedia\n",
    "#with open(\"C:\\Users\\s161328\\Downloads\\movies_dict.txt\") as f:\n",
    "with open(\"movies_dict.txt\") as f:\n",
    "    movies_dict = json.loads(f.read())\n",
    "movies_dict_keys = movies_dict.keys()\n",
    "movies_dict_keys_proc = [re.sub( \":\", \"\", m.lower()) for m in movies_dict_keys]\n",
    "total = 0\n",
    "\n",
    "# We add to each movie, two extra keys, \"Reviews\" and \"Reviews grade\"\n",
    "for movie in movies_dict.keys():\n",
    "    movies_dict[movie][\"Reviews\"] = []\n",
    "    movies_dict[movie][\"Reviews grade\"] = \"\"\n",
    "i = 0\n",
    "\n",
    "for title in title_filtered:\n",
    "    if re.sub(\":\", \"\", title.lower()) in movies_dict_keys_proc:\n",
    "        path = direct + filename_list[i] + \".html\"\n",
    "        #t = urllib2.urlopen(path).read()\n",
    "        t = codecs.open(path,'r').read()\n",
    "        soup = BeautifulSoup(t,'html.parser')\n",
    "        # From each review we extract all paragraph, that contain the movie review\n",
    "        page_paragraphs = [str(x) for x in list(soup.find_all('p'))]\n",
    "        clean_paragraphs = []\n",
    "        # We clean each paragraph, and if it contains the Copyright information, the paragraph is discarded\n",
    "        for paragraph in page_paragraphs:\n",
    "            try:\n",
    "                text = re.search(r'<p>(.+?)</p>', paragraph, re.DOTALL).group(1)\n",
    "                if (re.search(\"Copyright \\d+\",text) == None):\n",
    "                    clean_paragraphs.append(text.strip())\n",
    "            except:\n",
    "                pass \n",
    "        # All paragraphs are joined and cleaned from html characters\n",
    "        review_text = html2text.html2text(\"\\n\".join(clean_paragraphs).decode(\"utf-8\"))\n",
    "        j = movies_dict_keys_proc.index(re.sub(\":\", \"\", title.lower()))\n",
    "        # Reviews texts are added to the dictionary\n",
    "        movies_dict[movies_dict_keys[j]][\"Reviews\"].append(review_text)\n",
    "        i += 1\n",
    "# The resulting dictionary is saved in a txt file\n",
    "json.dump(movies_dict, open(\"movies_dict_with_reviews.txt\",'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, sentiment is calculated based on the reviews added to the dictionary in the previous section. Moreover, instead of using the dataset used in week 7 for calculating sentiment, we will generate the list of most important words for positive and negative reviews (with the associated value) given a list of highly polar reviews (saved in txt files).\n",
    "\n",
    "Some functions have to be defined for calculating sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculates the sentiment of a text, given a dictionary that matches words with punctuation\n",
    "def calculate_sentiment(text, sentiment_dict):\n",
    "    token_list = preprocess(text)\n",
    "    sent_keys_lower = [s.lower() for s in sentiment_dict.keys()]\n",
    "    intersect = [i for i in token_list if i in sent_keys_lower] #with repetitons\n",
    "    if (intersect == []): \n",
    "        print \"There are no sentiment words in the token list\"\n",
    "        return 0\n",
    "    return sum([sentiment_dict[i] for i in intersect])/len(token_list)\n",
    "\n",
    "# Processess and tokenizes a text\n",
    "def preprocess(raw):\n",
    "    \n",
    "    #We set the text to lowercase\n",
    "    raw = raw.lower()\n",
    "    \n",
    "    #We keep only the words\n",
    "    tokens = re.findall(r'[a-z]+', raw)\n",
    "    \n",
    "    #We create a exclusion list with the English stopwords\n",
    "    exclusion = stopwords.words('english')\n",
    "    \n",
    "    #We remove the exclusion list from the tokens\n",
    "    filtered_words = [w for w in tokens if not w in exclusion]\n",
    "    \n",
    "    #We remove morphological affixes from words, leaving only the word stem\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    filtered_words_stemmer = [stemmer.stem(t) for t in filtered_words]\n",
    "    \n",
    "    return filtered_words_stemmer\n",
    "\n",
    "#Function that returns a dictionary with the words as a key and their tf-idf value as a value\n",
    "def tfidf(words_counter, num_docs_containing, num_docs):\n",
    "    \n",
    "    #Dictionary with the words as a key and their tf-idf as a value\n",
    "    dict_tfidf = {key: \"\" for key in words_counter.keys()}\n",
    "    \n",
    "    for word in words_counter.keys():\n",
    "    \n",
    "        tf = words_counter[word]\n",
    "        try:\n",
    "            idf = np.log(num_docs/(1 + num_docs_containing[word]))\n",
    "        except KeyError:\n",
    "            idf = np.log(num_docs)\n",
    "        \n",
    "        dict_tfidf[word] = tf * idf\n",
    "        \n",
    "    return dict_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the text of all reviews is loaded and saved into a list, for both positive and negative reviews. Also, a string with the joined list is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Negative review is a list containing all negative reviews, and negative_reviews_str joins this list as a string\n",
    "negative_reviews = []\n",
    "#path = \"C:/Users/s161328/Downloads/movies_reviews_classified/neg\"\n",
    "path = \"/Users/Ferran/Downloads/movies_reviews_classified/neg\"\n",
    "for f in listdir(path):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(\"%s/%s\" %(path,f)) as neg_review:\n",
    "            # & character caused problems in html2text function (interpreted as EOF). Therefore, it was deleted.\n",
    "            neg_review_clean = re.sub(r\"\\&\",\"\",neg_review.read())\n",
    "            negative_reviews.append(html2text.html2text(neg_review_clean.decode(\"utf-8\")))\n",
    "negative_reviews_str = \" \".join(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Positive review is a list containing all negative reviews, and positive_reviews_str joins this list as a string\n",
    "positive_reviews = []\n",
    "#path = \"C:/Users/s161328/Downloads/movies_reviews_classified/pos\"\n",
    "path = \"/Users/Ferran/Downloads/movies_reviews_classified/pos\"\n",
    "for f in listdir(path):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(\"%s/%s\" %(path,f)) as pos_review:\n",
    "            pos_review_clean = re.sub(r\"\\&\",\"\",pos_review.read())\n",
    "            positive_reviews.append(html2text.html2text(pos_review_clean.decode(\"utf-8\")))\n",
    "positive_reviews_str = \" \".join(positive_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use TF-IDF to generate the sentiments words dictionaries, that assigns a value to a word according to the occurrence in positive and negative reviews. For this reason, we need to know, the number of times a word is used in the same-polarity reviews and the number of documents of the opposite polarity that contain this word. With all this information, we build two dictionaries, that give a punctuation to each word as a positive or as a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Processes and tokenizes the string with all the positive reviews\n",
    "positive_words_tokens = preprocess(positive_reviews_str)\n",
    "\n",
    "# Counts the number of docs that contain each word in positive_words_tokens in the list of negative reviews \n",
    "num_docs_containing_pos = Counter()\n",
    "positive_reviews_words_set = set(positive_words_tokens)\n",
    "negative_reviews_set = [set(preprocess(negative_reviews[i])) for i in xrange(len(negative_reviews))]\n",
    "\n",
    "for neg_word_token in negative_reviews_words_set:\n",
    "    for j in xrange(len(positive_reviews)):\n",
    "        if neg_word_token in positive_reviews_set[j]:\n",
    "            num_docs_containing_neg[neg_word_token] += 1\n",
    "json.dump(movies_dict, open(\"num_docs_containing_neg.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Processes and tokenizes the string with all the negative reviews\n",
    "negative_words_tokens = preprocess(negative_reviews_str)\n",
    "\n",
    "# Counts the number of docs that contain each word in negative_words_tokens in the list of positive reviews \n",
    "num_docs_containing_neg = Counter()\n",
    "negative_reviews_words_set = set(negative_words_tokens)\n",
    "positive_reviews_set = [set(preprocess(positive_reviews[i])) for i in xrange(len(positive_reviews))]\n",
    "\n",
    "for pos_word_token in positive_reviews_words_set:\n",
    "    for j in xrange(len(negative_reviews)):\n",
    "        if pos_word_token in negative_reviews_set[j]:\n",
    "            num_docs_containing_pos[pos_word_token] += 1\n",
    "json.dump(movies_dict, open(\"num_docs_containing_pos.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_words_counter = Counter(positive_words_tokens)\n",
    "json.dump(movies_dict, open(\"positive_words_counter.txt\",'w'))\n",
    "\n",
    "negative_words_counter = Counter(negative_words_tokens)\n",
    "json.dump(movies_dict, open(\"negative_words_counter.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Most of the code above takes much time to finish. For this reason we saved resulting dictionaries in txt files.\n",
    "# In this way, we can load the results and continue working another day\n",
    "\n",
    "with open(\"num_docs_containing_neg.txt\") as f:\n",
    "    num_docs_containing_neg = json.loads(f.read())\n",
    "\n",
    "with open(\"num_docs_containing_pos.txt\") as f:\n",
    "    num_docs_containing_pos = json.loads(f.read())\n",
    "    \n",
    "with open(\"positive_words_counter.txt\") as f:\n",
    "    positive_words_counter = json.loads(f.read())\n",
    "\n",
    "with open(\"negative_words_counter.txt\") as f:\n",
    "    negative_words_counter = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculation of both dictionaries, with values for posive and negative words\n",
    "tf_idf_neg = tfidf(negative_words_counter, num_docs_containing_neg, sum(negative_words_counter.values()))\n",
    "tf_idf_pos = tfidf(positive_words_counter, num_docs_containing_pos, sum(positive_words_counter.values()))\n",
    "max_tf_idf_neg = max(tf_idf_neg.values())\n",
    "max_tf_idf_pos = max(tf_idf_pos.values())\n",
    "max_tf_idf = max([max_tf_idf_neg, max_tf_idf_pos])\n",
    "sentiment_dict_neg = {tf_idf:-100*tf_idf_neg[tf_idf]/max_tf_idf for tf_idf in tf_idf_neg.keys()}\n",
    "sentiment_dict_pos = {tf_idf:100*tf_idf_pos[tf_idf]/max_tf_idf for tf_idf in tf_idf_pos.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the sentiment of each review is calculated as the addition of sentiment in both dictionaries, and the average of sentiment among the reviews in a movie is saved in \"Reviews grade\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"movies_dict_with_reviews.txt\") as f:\n",
    "    movies_dict = json.loads(f.read())\n",
    "# Given both sentiment dictionaries, the sentiment analysis for each movie with reviews is performed and the result is\n",
    "# saved in the \"Reviews grade\" key of the corresponding movie\n",
    "for movie in movies_dict.keys():\n",
    "    num_rev = len(movies_dict[movie][\"Reviews\"])\n",
    "    total_sent = 0\n",
    "    num_empty_rev = 0\n",
    "    if num_rev > 0:\n",
    "        for rev in movies_dict[movie][\"Reviews\"]:\n",
    "            aux = calculate_sentiment(rev, sentiment_dict_pos)\n",
    "            aux2 = calculate_sentiment(rev, sentiment_dict_neg) \n",
    "            # The sentiment of a specific review is the addition of the sentiment of positive and negative words\n",
    "            if(aux + aux2 != 0): total_sent = total_sent + aux + aux2\n",
    "            else: num_empty_rev += 1\n",
    "        movies_dict[movie][\"Reviews grade\"] = total_sent/(num_rev - num_empty_rev)\n",
    "json.dump(movies_dict, open(\"movies_dict_final.txt\",'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating the dictionary, we look for the movies with better and worse reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 movies by good reviews grade:\n",
      "1. Leviathan - 1.710\n",
      "2. Paradise - 1.151\n",
      "3. Texasville - 1.110\n",
      "4. Trespass - 1.039\n",
      "5. The Hills Have Eyes - 1.001\n",
      "6. Staying Together - 0.991\n",
      "7. Macbeth - 0.983\n",
      "8. See No Evil, Hear No Evil - 0.940\n",
      "9. The Rookie - 0.908\n",
      "10. Surveillance - 0.905\n"
     ]
    }
   ],
   "source": [
    "with open(\"movies_dict_final.txt\") as f:\n",
    "    movies_dict = json.loads(f.read())\n",
    "    \n",
    "movies_tuple_grade = [(movie,movies_dict[movie][\"Reviews grade\"]) for movie in movies_dict.keys()]\n",
    "movies_tuple_grade = [m for m in movies_tuple_grade if m[1] != '']\n",
    "movies_by_grade = sorted(movies_tuple_grade, key=itemgetter(1), reverse=True)\n",
    "top_number = 10\n",
    "print(\"The top %d movies by good reviews grade:\" % top_number)\n",
    "for i in xrange(top_number):\n",
    "    print(\"%d. %s - \" % ((i+1), movies_by_grade[i][0]) + '%.3f' % movies_by_grade[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There has been a good deal of discussion about unsung films (many of which\n",
      "among the film fans I know are at least somewhat \"sung\"). I want to recommend\n",
      "a film that I have never heard anyone else recommend. What makes it even odder\n",
      "is that it is a religious film and I generally hate religious films. This one\n",
      "didn't play fair, however: I already loved the film before I recognized the\n",
      "story or the allusion of the title! The film is Franco Zefferelli's 1973\n",
      "BROTHER SUN, SISTER MOON. It is one of the most beautiful films I have ever\n",
      "seen. Just about any frame of the film, blown up, could make a beautiful\n",
      "poster for the film. Music is by popular singer Donovan and the script bears\n",
      "four names (usually a bad sign), including Zefferelli and--of all people--Lina\n",
      "Wertmuller. Some people claim IT'S A WONDERFUL LIFE always has the power to\n",
      "cheer them up. Capra's film doesn't do that for me but this film does.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print movies_dict[\"Leviathan\"][\"Reviews\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director: Sidney Lumet Original Screenplay: Naomi Foner Director of\n",
      "Photography: Gerry Fisher Music: Tony Mottola Editor: Andrew Mondshein With\n",
      "River Phoenix, Christine Lahti, Judd Hirsch, Martha Plimpton, Jonas Abry, Ed\n",
      "Crowley, L.M. Kit Carson, Steven Hill, Augusta Dabney Sidney Lumet is one of\n",
      "my favourite directors. It's not difficult to forget that some of his films\n",
      "aren't great (\"The Appointment\", \"The Last of the Mobile Hotshots\", \"The\n",
      "Morning After\", \"A Stranger Among Us\", \"Guilty as Sin\"), because there are\n",
      "many superb motion pictures among his films, like \"Twelve Angry Men\", \"Long\n",
      "Day's Journey Into Night\", \"The Pawnbroker\", \"Serpico\", \"Dog Day Afternoon\",\n",
      "\"Network\", \"Prince of the City\", \"The Verdict\", the often underrated \"Q & A\"\n",
      "and this excellent drama \"RUNNING ON EMPTY\". In 1971, when they were radical\n",
      "students, Arthur and Annie Pope (Judd Hirsch, Christine Lahti) committed a\n",
      "bomb attack on a napalm laboratory to stop the war in Vietnam. Therefore they\n",
      "have been on the run for 15 years, chased by the FBI. Now they have two sons,\n",
      "17-year-old Danny (River Phoenix) and 10-year-old Harry (Jonas Abry), who must\n",
      "share their parents' destiny. In the first scenes of the film the Pope family\n",
      "must again change home and identities - as many times before. Now Danny falls\n",
      "in love for Lorna Phillips (Martha Plimpton), the daughter of his music\n",
      "teacher (Ed Crowley), who discovers Danny's musical talent and gets him to\n",
      "apply for a study at Juilliard School. But that would destroy the family.\n",
      "Danny gets into an inner conflict. On the one hand there are his love to Lorna\n",
      "and his wish to live his own life. On the other hand he wants to support his\n",
      "adored parents. When they notice that conflict, they don't know what to do\n",
      "either. With \"RUNNING ON EMPTY\" Sidney Lumet returns to the theme he has\n",
      "already treated in his film \"Daniel\" (1983). Lumet and his screenwriter Naomi\n",
      "Foner didn't want to make a political film in the first place. They wanted to\n",
      "show how children can be affected by the activities of their parents, and it's\n",
      "a film about the problems of families if the children want to leave home.\n",
      "Actually it would have been imaginable to treat this theme in front of a non-\n",
      "political background. But the political aspects enrich the film and stimulate\n",
      "us to discuss about what's more important: to change the world with dangerous\n",
      "actions or also to remember the consequences of these actions not only for\n",
      "one's own life, but for the lives of one's children too. By his quiet and\n",
      "sensitive direction Sidney Lumet creates a high inner suspense. And all the\n",
      "actors are - as usual in a Lumet film - excellent, especially River Phoenix,\n",
      "who earned a well deserved Academy Award nomination for his masterful\n",
      "performance (maybe the best in his much too short life), and Christine Lahti.\n",
      "Another remarkable point is the well considered editing with an apt use of\n",
      "dissolves and cuts. This is one of the best films I've seen up to now, a movie\n",
      "that you mustn't miss. My rating: ***** out of ***** (A MASTERPIECE)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print movies_dict[\"Paradise\"][\"Reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the two most positive reviews we can see that the sentiment analysis went quite good. For example, in *Leviathan* we can reed sentences such as \"**I already loved the film before I recognized the story**\" or \"**It is one of the most beautiful films I have ever seen**\", and in *Paradise* we can read sentences such as \"**This is one of the best films I've seen up to now, a movie that you mustn't miss**\", and qualifies it as a masterpiece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 movies by bad reviews grade:\n",
      "1. Shocker - -2.500\n",
      "2. The Guardian - -1.786\n",
      "3. Brothers - -1.347\n",
      "4. Jungle Fever - -1.294\n",
      "5. Megiddo: The Omega Code 2 - -1.148\n",
      "6. What About Bob? - -1.101\n",
      "7. The Great Gatsby - -1.082\n",
      "8. Fire Birds - -0.963\n",
      "9. Class of 1999 - -0.953\n",
      "10. Only the Strong - -0.937\n"
     ]
    }
   ],
   "source": [
    "movies_tuple_grade = [(movie,movies_dict[movie][\"Reviews grade\"]) for movie in movies_dict.keys()]\n",
    "movies_tuple_grade = [m for m in movies_tuple_grade if m[1] != '']\n",
    "movies_by_grade = sorted(movies_tuple_grade, key=itemgetter(1), reverse=False)\n",
    "top_number = 10\n",
    "print(\"The top %d movies by bad reviews grade:\" % top_number)\n",
    "for i in xrange(top_number):\n",
    "    print(\"%d. %s - \" % ((i+1), movies_by_grade[i][0]) + '%.3f' % movies_by_grade[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This has got to be the worst movie I've blown five bucks on in a very long\n",
      "time. Parts of it were, however, so bad that they were funny (Look, up in the\n",
      "sky, it's a bird, it's a plane - it's a statue! ). By the way, after\n",
      "irrelevant scene 1, superman saving Soviet spacecraft, when he hit the\n",
      "baseball in irrelevant scene 2, did anyone else think it was going to hit the\n",
      "spacecraft (Look out Ivan - here we go again!). All in all, S-man had a lousy\n",
      "week (used up his dad's green thing, violated the prime directive--non-\n",
      "interference--and had nothing to show for it). But seriously, why was the\n",
      "subplot about the Daily Planet takeover in the movie (to make it 2 hours\n",
      "long?)? Why was Mariel Hemingway in the movie (to be a damsel in distress for\n",
      "18 seconds?)? Chris Reeve did a really lousy job writing this. Why don't they\n",
      "get comic-book writers to write comic book movies?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print movies_dict[\"Shocker\"][\"Reviews\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyway, I know all you John Carpenter fans have been waiting years now since\n",
      "THE THING for a real Carpenter horror flick. Well, PRINCE OF DARKNESS isn't\n",
      "it. The premise of the rebirth of Satan on Earth is very badly set up with a\n",
      "lot of absurdly bad metaphysics and theology. The horror and suspense are nil\n",
      "--people stupidly wander off alone and you just know they're going to get it.\n",
      "First you see them walking down the hall, then all of a sudden, somebody\n",
      "appears from the side of screen and stabs them, breaks their neck, or spits at\n",
      "them and then the scene is over (this last part, from the appearance of the\n",
      "second person to the end of the scene, typically lasts 1.5 seconds). By the\n",
      "way, in case you're wondering \"Spits at them?\", well, that's supposed to be\n",
      "scary but as you can already tell just by reading about it, it's so stupid,\n",
      "you want to laugh every time it happens. There is no gore whatsoever. However,\n",
      "if you're into disgusting things, this movie might be for you. There are a lot\n",
      "of shots of worms and bugs and maggots and all those fun things. There's a\n",
      "nice long sequence in which one of the characters walks around with the worst\n",
      "skin affliction you've ever seen. And there's one really funny scene in which\n",
      "a man standing up is being eaten by zillions of bugs and his body parts start\n",
      "to fall off. Actually, a lot of the movie is so bad that it's funny. Other\n",
      "comments: the music never stops and it gets really annoying really fast; the\n",
      "intro credits are interspersed with the beginning of the movie so that it\n",
      "takes about 10 minutes before they're all done with; the acting is really lame\n",
      "(most of the actors I recognized from TV series), the worst being Donald\n",
      "Pleasance as a priest; and, finally, this movie has the highest Asian count--3\n",
      "--among all movies (I know of) in which the characters' races were irrelevant.\n",
      "Rating? 0 on -4/+4, $1/Cable on $(1st view/2nd view) and maybe 2 on S&N.;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print movies_dict[\"The Guardian\"][\"Reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the two worst reviews, we can find senteces like \"**This has got to be the worst movie I've blown five bucks on in a very long time**\" in *Shocker* or \"**a lot of the movie is so bad that it's funny**\" in *The Guardian*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
